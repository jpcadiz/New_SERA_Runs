{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf10e8b8-e919-4765-a670-c54ed4b1e9bf",
   "metadata": {},
   "source": [
    "SERA Outout Figs version 2\n",
    "Working on several things:\n",
    " - making the construction file expand to include every year of the technology lifetime (DONE)\n",
    " - removing cost from flow file (according to Justin's email 5/10/23) (DONE)\n",
    " - including pulling in feedstock intensities and costs to calculate feedstock costs (DONE)\n",
    " - updating figure set\n",
    "     - output maps\n",
    " - outputing some summary csv files to make it easier to make comparison figs across scenarios\n",
    "     - to compare across scenarios (same as many figures)\n",
    "         - levelized cost\n",
    "         - production & delivery mix\n",
    "         - \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1999b1b-b2e6-4351-b1b5-5abc50d1dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# CELL #1 # Imports and directory of folders goes here\n",
    "###########\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import yaml\n",
    "import math\n",
    "import folium\n",
    "pd.set_option('display.max_columns', 500)\n",
    "files=[\n",
    "\n",
    "    \n",
    "#     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA_5Db_prodCF_newLocs/', 'const':'construction_SERA_2.tsv',\n",
    "#         'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA_5Db_prodCF_newLocs','name':'BaseA_5Db_prodCF_newLocs'},\n",
    "#     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA_10Db_prodCF_newLocs/', 'const':'construction_SERA_2.tsv',\n",
    "#         'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA_10Db_prodCF_newLocs','name':'BaseA_10Db_prodCF_newLocs'},\n",
    "#     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA_15Db_prodCF_newLocs/', 'const':'construction_SERA_2.tsv',\n",
    "#         'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA_15Db_prodCF_newLocs','name':'BaseA_15Db_prodCF_newLocs'},\n",
    "#     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA_20Db_prodCF_newLocs/', 'const':'construction_SERA_2.tsv',\n",
    "#         'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA_20Db_prodCF_newLocs','name':'BaseA_20Db_prodCF_newLocs'},\n",
    "#     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA_25Db_prodCF_newLocs/', 'const':'construction_SERA_2.tsv',\n",
    "#         'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA_25Db_prodCF_newLocs','name':'BaseA_25Db_prodCF_newLocs'},\n",
    "     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA1_25Db_0DR/', 'const':'construction_SERA_2.tsv',\n",
    "        'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA1_25Db_0DR','name':'BaseA1_25Db_0DR'},\n",
    "     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA1_25Db_3DR/', 'const':'construction_SERA_2.tsv',\n",
    "        'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA1_25Db_3DR','name':'BaseA1_25Db_3DR'},\n",
    "     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA1_25Db_6DR/', 'const':'construction_SERA_2.tsv',\n",
    "        'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA1_25Db_6DR','name':'BaseA1_25Db_6DR'},\n",
    "     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA1_25Db_9DR/', 'const':'construction_SERA_2.tsv',\n",
    "        'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA1_25Db_9DR','name':'BaseA1_25Db_9DR'},\n",
    "     {'folder':'../SERA/SERA_NEW_OUTPUTS/BaseA1_25Db_12DR/', 'const':'construction_SERA_2.tsv',\n",
    "        'flow':'flow_SERA_2.tsv','geo':'GEOMETRY/geometry_high.tsv','code':'BaseA1_25Db_12DR','name':'BaseA1_25Db_12DR'},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a4d9d0-5009-4f07-afbc-dbc4a498a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# CELL #2 # All of the function declarations are here\n",
    "###########\n",
    "\n",
    "def initDeliveryNetworks():\n",
    "    fp=open('scenarios.js','w')\n",
    "    fp.write(\"files=\"+str(files)+\";\\n\")\n",
    "    fp.close()\n",
    "\n",
    "def CRF(rate,lifetime):\n",
    "    return (rate*(1+rate)**lifetime)/((1+rate)**lifetime-1)\n",
    "\n",
    "def get_key_files_from_YAML():\n",
    "    with open(folder+\"scenario.yaml\", 'r') as stream:\n",
    "        data_loaded = yaml.safe_load(stream)\n",
    "        delinputs=data_loaded['processLibraryFiles'][2]['inputsFile']\n",
    "        prodinputs=data_loaded['processLibraryFiles'][0]['inputsFile']\n",
    "        prices=data_loaded['priceFiles'][0]\n",
    "        zonefile=data_loaded['networkFiles']['zoneFiles'][0]\n",
    "        nodefile=data_loaded['networkFiles']['nodeFiles'][0]\n",
    "        demandfile=data_loaded['demandFiles'][0]\n",
    "        linksfile=data_loaded['networkFiles']['linkFiles'][0]\n",
    "    \n",
    "    return [delinputs,prodinputs,prices,zonefile,nodefile,demandfile,linksfile]\n",
    "\n",
    "def closest(K,lst): \n",
    "    ind=min(range(len(lst)), key = lambda i: abs(lst[i]-K))\n",
    "    return [ind,lst[ind]]\n",
    "\n",
    "def bracket(K,lst):\n",
    "    above = min([i for i in lst if K < i])\n",
    "    below = max([i for i in lst if K > i])\n",
    "\n",
    "    return [[below,lst.index(below)],[above,lst.index(above)]]\n",
    "\n",
    "def get_category1(row):\n",
    "    tech = row['Technology']\n",
    "    cat=\"\"\n",
    "    if tech in stationlist:\n",
    "        cat=\"stations\"\n",
    "    elif tech in plantlist:\n",
    "        cat=\"production\"\n",
    "    elif tech in delivery_components:\n",
    "        cat=\"delivery\"\n",
    "    return cat\n",
    "\n",
    "def get_Pathway(row):\n",
    "    tech = row['Technology']\n",
    "    cat=\"\"\n",
    "    if tech in gastruck_components:\n",
    "        cat=\"GH2\"\n",
    "    elif tech in plantlist:\n",
    "        cat=\"production\"\n",
    "    elif tech in liqtruck_components:\n",
    "        cat=\"LH2\"\n",
    "    elif tech in pipeline_components:\n",
    "        cat=\"pipe\"\n",
    "    return cat\n",
    "\n",
    "def table_scale_interpolation_v2(value,xcol,ycol,df_sub,extrapolationtype):\n",
    "    #extrapolationtype 1 is cost extrapolation where you extrapolate by scaling\n",
    "    #extrapolationtype 0 is intensity (consumption) extrapolation where you take last value\n",
    "    # xvals=[]\n",
    "    # yvals=[]\n",
    "    # for index,row in df_sub.iterrows():\n",
    "    #     xvals.append(row[xcol])\n",
    "    #     yvals.append(row[ycol])\n",
    "    answer=0\n",
    "    if len(df_sub)>0:\n",
    "        xvals=list(df_sub[xcol])\n",
    "        yvals=list(df_sub[ycol])\n",
    "        # print(xvals,yvals)\n",
    "        if value>min(xvals) and value < max(xvals):\n",
    "            # print(\"within\")\n",
    "            # closest_x=closest(value,xvals)\n",
    "            [[x0,i0],[x1,i1]]= bracket(value,xvals)\n",
    "            y0=yvals[i0]\n",
    "            y1=yvals[i1]\n",
    "            scalefactor=math.log(y1/y0)/math.log(x1/x0)\n",
    "            # ratio=\n",
    "            # print(y0,value,x0,scalefactor)\n",
    "            answer=y0*(value/x0)**scalefactor\n",
    "        else:\n",
    "            # print(\"outside\")\n",
    "            if value<min(xvals):\n",
    "                answer=yvals[0]\n",
    "            if value>max(xvals):\n",
    "                if extrapolationtype==1:\n",
    "                    answer=yvals[-1]*(value/xvals[-1])\n",
    "                if extrapolationtype==0:\n",
    "                    answer=yvals[-1]\n",
    "    else:\n",
    "        answer=0\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def getDFSubset_Inputs(technology,year):\n",
    "    year_fix=roundYear(year)\n",
    "    # print(year_fix)\n",
    "    dfsub=inputsdf[(inputsdf['Technology']==technology)&(inputsdf['Year']==year_fix)]\n",
    "    #checks if returning dataframe is empty (i.e. no technology costs specified in this year)\n",
    "    if len(dfsub)==0:\n",
    "        # print('zero')\n",
    "        #recursively call this same function on year - 1 (until it finds a year with costs) \n",
    "        dfsub=getDFSubset_Inputs(technology,year-1)\n",
    "    return dfsub\n",
    "\n",
    "def get_nearest_year_before(year,yearlist):\n",
    "    ## gets closest year that is before a given year from a list of candidate years\n",
    "    nearest_yr=yearlist[0]\n",
    "    for yr_opt in yearlist:\n",
    "        if yr_opt<=year:\n",
    "            nearest_yr=yr_opt\n",
    "    return nearest_yr    \n",
    "\n",
    "def graph_aggregate_lev_cost():\n",
    "    tmp=seraflow_full\n",
    "    tmp_summary=tmp.groupby(['Year']).sum()\n",
    "    tmp_summary=tmp_summary.reset_index()\n",
    "\n",
    "    tmp_summary=tmp_summary.merge(annual_station_df,left_on='Year', right_index=True)\n",
    "    tmp_summary['Lev Cost']=tmp_summary['Total Annual Cost']/(tmp_summary['Fueling-Station Demand [kg]'])\n",
    "    \n",
    "    tmp_summary2=tmp_summary[['Lev Cost','Total Annual Cost']]\n",
    "    tmp_summary2.to_csv(outputsfolder +\"lev_ann_cost.csv\")\n",
    "    # display(tmp_summary)\n",
    "    # years=list(range(2026,2051))\n",
    "    fig, ax = plt.subplots(figsize =(10, 6))\n",
    "    bars=ax.bar(tmp_summary['Year'],tmp_summary['Lev Cost'])\n",
    "    ax.bar_label(bars,fmt='%.1f')\n",
    "    ax.set_title(\"H2 Levelized Cost\", fontsize=20)\n",
    "    ax.set_xlabel('Year', fontsize=18)\n",
    "    ax.set_ylabel('Levelized Cost ($/kg)', fontsize=18)\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder + 'Total lev cost.png', dpi=300)\n",
    "    \n",
    "def graph_annual_costs():\n",
    "    \n",
    "    tmp=seraflow_full\n",
    "#     display(tmp['Technology'].value_counts())\n",
    "    tmp_summary=tmp.groupby(['Technology','Year']).sum()\n",
    "#     tmp_summary['Lev Cost']=tmp_summary['Total Annual Cost']/(tmp_summary['Flow_kg']+tmp_summary['Production_kg'])\n",
    "#     tmp_summary['CF']=(tmp_summary['Flow_kg']+tmp_summary['Production_kg'])/tmp_summary['Nameplate_Capacity']        \n",
    "    tmp_summary=tmp_summary.reset_index()\n",
    "    components=list(tmp_summary['Technology'].unique())\n",
    "    # display(tmp_summary)\n",
    "    years=list(range(2026,2051))\n",
    "    graphitems={}\n",
    "    df1 = pd.DataFrame(years,columns =['Year'])\n",
    "    for i in range(0,len(components)):\n",
    "        # print(i)\n",
    "        df1=df1.merge(tmp_summary[tmp_summary['Technology']==components[i]][['Year', 'Total Annual Cost']], how = 'left', on=\"Year\")\n",
    "        df1=df1.rename(columns = {'Total Annual Cost':components[i]})\n",
    "#         graphitems[components[i]]=list(tmp_summary[tmp_summary['Technology']==components[i]]['Total Annual Cost'])\n",
    "        graphitems[components[i]]=list(df1[components[i]])\n",
    "        \n",
    "    graphitems\n",
    "    graph = pd.DataFrame(graphitems, index=years)\n",
    "    # export to csv\n",
    "    graph.to_csv(outputsfolder +\"tech_annual_cost.csv\")\n",
    "    \n",
    "    ax = graph.plot.bar(rot=0,stacked=True,figsize=(12, 6))\n",
    "    ax.set_ylabel(\"Annual Cost ($)\")\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder + 'annual cap cost.png', dpi=300)\n",
    "    \n",
    "    return tmp_summary\n",
    "\n",
    "def graph_production_delivery_mix():\n",
    "    \n",
    "    productionlist=plantlist\n",
    "    deliverylist=stationlist\n",
    "    \n",
    "    tmp=seraflow_full[seraflow_full['Technology'].isin(productionlist)]\n",
    "    tmpg=tmp.groupby(['Technology','Year']).sum().reset_index()\n",
    "    tmpg['Cap_t_d']=tmpg['Nameplate_Capacity']/365000\n",
    "    tmpg['Prod_t_d']=tmpg['Production_kg']/365000\n",
    "    \n",
    "    #production graphs\n",
    "    tmpg2=tmpg.pivot(index='Year',columns='Technology',values='Cap_t_d')\n",
    "    ax=tmpg2.plot(kind='bar', stacked=True)\n",
    "    ax.set_ylabel(\"Production Capacity mix (t/d)\")\n",
    "    plt.savefig(outputsfolder+'production capacity mix.png', dpi=300)\n",
    "    \n",
    "    tmpg3=tmpg.pivot(index='Year',columns='Technology',values='Prod_t_d')\n",
    "    ax=tmpg3.plot(kind='bar', stacked=True)\n",
    "    ax.set_ylabel(\"Production mix (t/d)\")\n",
    "    plt.savefig(outputsfolder+'production flow mix.png', dpi=300)\n",
    "    tmpg4=pd.merge(tmpg2, tmpg3, left_index=True, right_index=True)\n",
    "    tmpg4=tmpg4.rename(columns = {'Central Grid Electrolysis (PEM)_x':'Grid PEM Cap','Central Grid Electrolysis (PEM)_y':'Grid PEM Flow',\n",
    "                                  'Central Ren Electrolysis (PEM-REN)_x':'Ren Pem Cap','Central Ren Electrolysis (PEM-REN)_y':'Ren Pem Flow',\n",
    "                                  'Central Natural Gas Reforming w/CCS_x':'NG CCS Cap','Central Natural Gas Reforming w/CCS_y':'NG CCS Flow',\n",
    "                                 'Central Natural Gas Reforming (no CCS)_x':'NG SMR Cap','Central Natural Gas Reforming (no CCS)_y':'NG SMR Flow'})\n",
    "    tmpg4.to_csv(outputsfolder +\"production mix.csv\")\n",
    "    \n",
    "    #delivery grpahs\n",
    "    tmp=seraflow_full[seraflow_full['Technology'].isin(deliverylist)]\n",
    "    if tmp.shape[0]!=0:\n",
    "        tmpg=tmp.groupby(['Technology','Year']).sum().reset_index()\n",
    "        tmpg['Cap_t_d']=tmpg['Nameplate_Capacity']/365000\n",
    "        tmpg['Flow_t_d']=tmpg['Flow_kg']/365000\n",
    "        tmpg2=tmpg.pivot(index='Year',columns='Technology',values='Cap_t_d')\n",
    "        ax=tmpg2.plot(kind='bar', stacked=True)\n",
    "        ax.set_ylabel(\"Delivery Capacity mix (t/d)\")\n",
    "        plt.savefig(outputsfolder+'delivery capacity mix.png', dpi=300)\n",
    "        tmpg3=tmpg.pivot(index='Year',columns='Technology',values='Flow_t_d')\n",
    "        ax=tmpg3.plot(kind='bar', stacked=True)\n",
    "        ax.set_ylabel(\"Delivery mix (t/d)\")\n",
    "        if hidefigs:\n",
    "            plt.close()\n",
    "        plt.savefig(outputsfolder+'delivery flow mix.png', dpi=300)\n",
    "        tmpg4=pd.merge(tmpg2, tmpg3, left_index=True, right_index=True)\n",
    "        tmpg4=tmpg4.rename(columns = {'GH2 Pipeline Station (700bar)_x':'Pipe Cap','GH2 Truck Station (700bar)_x':'GH2 Cap','LH2 Station (gas dispensing)_x':'LH2 Cap','GH2 Pipeline Station (700bar)_y':'Pipe Flow','GH2 Truck Station (700bar)_y':'GH2 Flow','LH2 Station (gas dispensing)_y':'LH2 Flow'})\n",
    "        tmpg4.to_csv(outputsfolder +\"delivery mix.csv\")\n",
    "        \n",
    "def graph_delivery_distances():\n",
    "    deliverylinks=[([\"GH2 Truck Link Var\"],\"GH2 Truck Station (700bar)\"),\n",
    "                ([\"LH2 Truck Link Var\"],\"LH2 Station (gas dispensing)\"),\n",
    "                ([\"GH2 Pipeline (transmission)\",'Linepack pipeline (transmission)'],\"GH2 Pipeline Station (700bar)\"),\n",
    "                   # ([\"GH2 Truck Link\",'GH2 Truck Station (700bar)'],\"GH2 Truck Station (700bar)\"),\n",
    "              ]\n",
    "    # data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "    avgdists={\"Year\":[],\n",
    "            \"GH2 Truck Link Var\":[],\n",
    "             \"LH2 Truck Link Var\":[],\n",
    "             \"GH2 Pipeline (transmission)\":[]\n",
    "             }\n",
    "    for yr in range(2025,2051):\n",
    "        avgdists['Year'].append(yr)\n",
    "        for i in range(0,3):\n",
    "            if len(deliverylinks[i][0])==1:\n",
    "                tmpa=seraflow_full[(seraflow_full['Technology']==deliverylinks[i][0][0])&(seraflow_full['Year']==yr)]\n",
    "            else:\n",
    "                tmpa=seraflow_full[((seraflow_full['Technology']==deliverylinks[i][0][0])|(seraflow_full['Technology']==deliverylinks[i][0][1]))&(seraflow_full['Year']==yr)]\n",
    "                # display(tmpa)\n",
    "            tmpb=seraflow_full[(seraflow_full['Technology']==deliverylinks[i][1])&(seraflow_full['Year']==yr)]\n",
    "            prod_distxflow=(tmpa['Flow_kg']*tmpa['Length']).sum()\n",
    "            tot_flow=tmpb['Flow_kg'].sum()\n",
    "            # print(prod_distxflow,tot_flow,prod_distxflow/tot_flow)\n",
    "            avgdists[deliverylinks[i][0][0]].append(prod_distxflow/tot_flow)\n",
    "\n",
    "    tmpc=pd.DataFrame.from_dict(avgdists).fillna(0)\n",
    "    fig, ax1 = plt.subplots(figsize =(10, 6))\n",
    "    ax1.bar(tmpc['Year']-.25, tmpc['GH2 Truck Link Var'],width = 0.25, align='center')\n",
    "    ax1.bar(tmpc['Year'], tmpc['LH2 Truck Link Var'],width = 0.25, align='center')\n",
    "    ax1.bar(tmpc['Year']+.25, tmpc['GH2 Pipeline (transmission)'],width = 0.25, align='center')\n",
    "    ax1.set_title(\"Weighted Avg Delivery Distances\")\n",
    "    ax1.set_ylabel('Avg Delivery Distance (km)')\n",
    "    ax1.legend(labels=[\"GH2 Truck Links\",\"LH2 Truck Links\",\"Pipelines\"],loc='upper right', frameon=False)\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder + 'Avg Del Distance.png', dpi=300)\n",
    "    \n",
    "def production_location():\n",
    "    plants=plantlist\n",
    "    # df[df['A'].isin([3, 6])]\n",
    "    tmpdf=seraconstruction[seraconstruction['Technology'].isin(plants)].groupby(['Network_ID','Year']).sum()\n",
    "    # tmpdf.droplevel(level=1)\n",
    "    tmpdf=tmpdf.reset_index()\n",
    "\n",
    "    tmpdf=tmpdf.pivot_table(index = 'Year', columns = 'Network_ID' , values = 'DailyCap').fillna(0)\n",
    "    ax=tmpdf.plot(kind = 'bar', stacked = True,figsize=(10,6))\n",
    "    ax.set_ylabel(\"Added Capacity (t/d)\")\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_title(\"Capacity Additions by Region\")\n",
    "    plt.savefig(outputsfolder+'Plant Capacity Additions.png', dpi=300)\n",
    "\n",
    "    tmpdf2=tmpdf.cumsum()\n",
    "    ax2=tmpdf2.plot(kind = 'bar', stacked = True,figsize=(10,6))\n",
    "    ax2.set_ylabel(\"Total Capacity (t/d)\")\n",
    "    ax2.set_xlabel(\"Year\")\n",
    "    ax2.set_title(\"Cumulative Capacity by Region\")\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder+'Plant Capacity Cumulative.png', dpi=300)\n",
    "    \n",
    "def caps_and_flows():\n",
    "    stationdf=seraflow_full[seraflow_full['Technology'].isin(stationlist)].groupby('Year').sum()[['Flow_kg','DailyCap']].rename(columns={'Flow_kg':'Station_kg','DailyCap':'Station_cap'})\n",
    "    stationdf['Station_flow']=stationdf['Station_kg']/365000\n",
    "    proddf=seraflow_full[seraflow_full['Technology'].isin(plantlist)].groupby('Year').sum()[['Production_kg','DailyCap']].rename(columns={'Production_kg':'Prod_kg','DailyCap':'Prod_cap'})\n",
    "    proddf['Prod_flow']=proddf['Prod_kg']/365000\n",
    "    flows=proddf.merge(stationdf, on=\"Year\")\n",
    "    flows=flows.reset_index()\n",
    "    flows['Prod_CF']=flows['Prod_flow']/flows['Prod_cap']\n",
    "    flows['Station_CF']=flows['Station_flow']/flows['Station_cap']\n",
    "    # display(flows)\n",
    "    prodtot=flows['Prod_flow'].sum()\n",
    "    prodcap=flows['Prod_cap'].sum()\n",
    "    stattot=flows['Station_flow'].sum()\n",
    "    statcap=flows['Station_cap'].sum()\n",
    "    # print(prodtot,prodcap,prodtot/prodcap,stattot,statcap,stattot/statcap)\n",
    "    fig, ax1 = plt.subplots(1,1,figsize=(10, 6))\n",
    "\n",
    "        # These are in unitless percentages of the figure size. (0,0 is bottom left)\n",
    "    left, bottom, width, height = [.2, .66, 0.3, 0.2]\n",
    "    ax2 = fig.add_axes([left, bottom, width, height])\n",
    "    # fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "    # ax2 = ax1.twinx() \n",
    "    # plt.figure(figsize=(10,6))\n",
    "    ax1.plot(flows['Year'],flows['Prod_flow'],label=\"Production flow\",color='blue')\n",
    "    ax1.plot(flows['Year'],flows['Station_flow'],label=\"Station flow\",color='orange')\n",
    "    ax1.plot(flows['Year'],flows['Prod_cap'],label=\"Production capacity\",color='blue', linestyle='dashed')\n",
    "    ax2.plot(flows['Year'],flows['Prod_CF'],label=\"Production cap factor\",color='blue', linestyle='dotted',linewidth=3)\n",
    "    ax1.plot(flows['Year'],flows['Station_cap'],label=\"Station capacity\",color='orange', linestyle='dashed')\n",
    "    ax2.plot(flows['Year'],flows['Station_CF'],label=\"Station cap factor\",color='orange', linestyle='dotted',linewidth=3)\n",
    "    ax1.set_xlabel(\"Year\")\n",
    "    ax1.set_ylabel(\"H2 Capacity or Flows (tonnes/day)\")\n",
    "    ax2.set_ylabel(\"Capacity Factors\")\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    # ax2.legend(loc=\"lower right\")\n",
    "    # plt.title('multiple plots')\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder+'capacities and flows.png', dpi=300)\n",
    "    \n",
    "def storageflows():\n",
    "    tmp=seraflow_full[seraflow_full['Variable'].str.contains('Storage')]\n",
    "    if len(tmp)>0:\n",
    "        tmp=tmp.groupby(['Year','Variable']).sum().reset_index()\n",
    "        tmp=tmp.pivot(index='Year',columns='Variable',values='Flow_kg')\n",
    "        tmp=tmp.fillna(0).reset_index()\n",
    "        tmp['net']=tmp['Storage In']-tmp['Storage Out']\n",
    "\n",
    "        # tmp2=seraflow_full[seraflow_full['Storage_Capacity']>0]\n",
    "        # tmp2=tmp2.groupby(['Year','Infrastucture_ID']).first().reset_index()\n",
    "        # # tmp2[tmp2['Infrastucture_ID']==\"INFR_STORAGE_PL_CA1_PipelineNodalStorage_1_2030\"]\n",
    "        # tmp2=tmp2.groupby(['Year']).sum().reset_index()\n",
    "\n",
    "        # tmpg2=tmpg.pivot(index='Year',columns='Technology',values='Cap_t_d')\n",
    "        fig, ax1 = plt.subplots(1,1,figsize=(10, 6))\n",
    "        ax1.plot(tmp['Year'],tmp['Storage In']/365000,label=\"Storage In\",color='blue')\n",
    "        ax1.plot(tmp['Year'],-tmp['Storage Out']/365000,label=\"Storage Out\",color='orange')\n",
    "        ax1.plot(tmp['Year'],tmp['net']/365000,label=\"Net Storage In\",color='black')\n",
    "        # ax1.plot(tmp['Year'],tmp2['DailyCap'],label=\"Storage Capacity\",color='black',linestyle='dashed')\n",
    "        plt.axhline(0, color='grey')\n",
    "        ax1.legend(loc=\"upper left\")\n",
    "        ax1.set_ylabel(\"Storage Flows (tonnes/day)\")\n",
    "        print(tmp['Storage In'].sum()/365000,\"tonnes/day\",tmp['Storage Out'].sum()/365000,\"tonnes/day\")\n",
    "        if hidefigs:\n",
    "            plt.close()\n",
    "        plt.savefig(outputsfolder+'storageflows.png', dpi=300)\n",
    "    \n",
    "def graph_delivery_distances():\n",
    "    deliverylinks=[([\"GH2 Truck Link Var\"],\"GH2 Truck Station (700bar)\"),\n",
    "                ([\"LH2 Truck Link Var\"],\"LH2 Station (gas dispensing)\"),\n",
    "                ([\"GH2 Pipeline (transmission)\",'Linepack pipeline (transmission)'],\"GH2 Pipeline Station (700bar)\"),\n",
    "                   # ([\"GH2 Truck Link\",'GH2 Truck Station (700bar)'],\"GH2 Truck Station (700bar)\"),\n",
    "              ]\n",
    "    # data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "    avgdists={\"Year\":[],\n",
    "            \"GH2 Truck Link Var\":[],\n",
    "             \"LH2 Truck Link Var\":[],\n",
    "             \"GH2 Pipeline (transmission)\":[]\n",
    "             }\n",
    "    for yr in range(2025,2051):\n",
    "        avgdists['Year'].append(yr)\n",
    "        for i in range(0,3):\n",
    "            if len(deliverylinks[i][0])==1:\n",
    "                tmpa=seraflow_full[(seraflow_full['Technology']==deliverylinks[i][0][0])&(seraflow_full['Year']==yr)]\n",
    "            else:\n",
    "                tmpa=seraflow_full[((seraflow_full['Technology']==deliverylinks[i][0][0])|(seraflow_full['Technology']==deliverylinks[i][0][1]))&(seraflow_full['Year']==yr)]\n",
    "                # display(tmpa)\n",
    "            tmpb=seraflow_full[(seraflow_full['Technology']==deliverylinks[i][1])&(seraflow_full['Year']==yr)]\n",
    "            prod_distxflow=(tmpa['Flow_kg']*tmpa['Length']).sum()\n",
    "            tot_flow=tmpb['Flow_kg'].sum()\n",
    "            # print(prod_distxflow,tot_flow,prod_distxflow/tot_flow)\n",
    "            avgdists[deliverylinks[i][0][0]].append(prod_distxflow/tot_flow)\n",
    "\n",
    "    tmpc=pd.DataFrame.from_dict(avgdists).fillna(0)\n",
    "    fig, ax1 = plt.subplots(figsize =(10, 6))\n",
    "    ax1.bar(tmpc['Year']-.25, tmpc['GH2 Truck Link Var'],width = 0.25, align='center')\n",
    "    ax1.bar(tmpc['Year'], tmpc['LH2 Truck Link Var'],width = 0.25, align='center')\n",
    "    ax1.bar(tmpc['Year']+.25, tmpc['GH2 Pipeline (transmission)'],width = 0.25, align='center')\n",
    "    ax1.set_title(\"Avg Delivery Distances\")\n",
    "    ax1.set_ylabel('Avg Delivery Distance (km)')\n",
    "    ax1.legend(labels=[\"GH2 Truck Links\",\"LH2 Truck Links\",\"Pipelines\"],loc='upper right', frameon=False)\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder + 'Avg Del Distance.png', dpi=300)\n",
    "        \n",
    "def category_levelized_cost():\n",
    "    tmp=seraflow_full\n",
    "    tmp_summary=tmp.groupby(['Category','Year']).sum()\n",
    "    # display(tmp_summary.head(50))\n",
    "    tmp_summary=tmp_summary.reset_index()\n",
    "    tmp_summary=tmp_summary.merge(annual_station_df,left_on='Year', right_index=True)\n",
    "    # display(tmp_summary)\n",
    "    tmp_summary['Lev Cost']=tmp_summary['Total Annual Cost']/(tmp_summary['Fueling-Station Demand [kg]'])\n",
    "    \n",
    "    tmp_summary=tmp_summary.pivot(index='Year',columns='Category',values='Lev Cost')\n",
    "    tmp_summary=tmp_summary[['production','delivery','stations']]\n",
    "    tmp_summary.index = tmp_summary.index.astype(int)\n",
    "\n",
    "    ax = tmp_summary.plot.bar(rot=0,stacked=True,figsize=(10, 6))\n",
    "    ax.set_ylabel(\"Levelized Cost ($/kg)\")\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder + 'Category lev cost.png', dpi=300)\n",
    "    \n",
    "def CapOpFeed_levelized_cost():\n",
    "    tmp=seraflow_full    \n",
    "    tmp_summary=tmp.groupby(['Year']).sum()\n",
    "    tmp_summary=tmp_summary.reset_index()\n",
    "    \n",
    "    \n",
    "    # tmp_summary['Annual Cap']+tmp_summary['O&M Cost (Fix+Var)']+tmp_summary['Feedstock Annual Cost']\n",
    "    tmp_summary=tmp_summary.merge(annual_station_df,left_on='Year', right_index=True)\n",
    "    tmp_summary['Cap Lev Cost']=tmp_summary['Annual Cap']/(tmp_summary['Fueling-Station Demand [kg]'])\n",
    "    tmp_summary['Op Lev Cost']=tmp_summary['O&M Cost (Fix+Var)']/(tmp_summary['Fueling-Station Demand [kg]'])\n",
    "    tmp_summary['Feed Lev Cost']=tmp_summary['Feedstock Annual Cost']/(tmp_summary['Fueling-Station Demand [kg]'])\n",
    "\n",
    "    tmp_summary2=tmp_summary[['Year','Annual Cap','O&M Cost (Fix+Var)','Feedstock Annual Cost']]\n",
    "    tmp_summary2=tmp_summary2.set_index('Year')\n",
    "    tmp_summary2['Annual Cap']=tmp_summary2['Annual Cap']/1e9\n",
    "    tmp_summary2['Annual Op']=tmp_summary2['O&M Cost (Fix+Var)']/1e9\n",
    "    tmp_summary2['Annual Feed']=tmp_summary2['Feedstock Annual Cost']/1e9\n",
    "    tmp_summary2=tmp_summary2[['Annual Cap','Annual Op','Annual Feed']]\n",
    "    tmp_summary2\n",
    "    ax=tmp_summary2.plot(kind='bar', stacked=True)\n",
    "    ax.set_ylabel(\"Annual Cost Components ($B/yr)\")\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder+'Annual Cost Components.png', dpi=300)\n",
    "    tmp_summary3=tmp_summary[['Year','Cap Lev Cost','Op Lev Cost','Feed Lev Cost']]\n",
    "    tmp_summary3=tmp_summary3.set_index('Year')\n",
    "    tmp_summary3\n",
    "    ax=tmp_summary3.plot(kind='bar', stacked=True)\n",
    "    ax.set_ylabel(\"Levelized Cost Components ($/kg)\")\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder+'Levelized Cost Components.png', dpi=300)\n",
    "    \n",
    "\n",
    "    \n",
    "def pathway_levelized_cost():\n",
    "    tmp=seraflow_full\n",
    "    tmp_summary=tmp.groupby(['Pathway','Year']).sum()\n",
    "    # display(tmp_summary.head(50))\n",
    "    tmp_summary=tmp_summary.reset_index()\n",
    "    tmp_summary=tmp_summary.merge(annual_station_df,left_on='Year', right_index=True)\n",
    "    # display(tmp_summary)\n",
    "    tmp_summary['Lev Cost']=tmp_summary['Total Annual Cost']/(tmp_summary['Fueling-Station Demand [kg]'])\n",
    "    \n",
    "    tmp_summary=tmp_summary.pivot(index='Year',columns='Pathway',values='Lev Cost')\n",
    "    missing=set(['production','GH2','LH2','pipe']).difference(set(list(tmp_summary.columns)))\n",
    "    for item in missing:\n",
    "        tmp_summary[item]=0\n",
    "    tmp_summary=tmp_summary[['production','GH2','LH2','pipe']]\n",
    "    tmp_summary.index = tmp_summary.index.astype(int)\n",
    "    \n",
    "\n",
    "    ax = tmp_summary.plot.bar(rot=0,stacked=True,figsize=(12, 6))\n",
    "    ax.set_ylabel(\"Levelized Cost ($/kg)\")\n",
    "    if hidefigs:\n",
    "        plt.close()\n",
    "    plt.savefig(outputsfolder + 'Pathway lev cost.png', dpi=300)\n",
    "    \n",
    "def parse_geometry_col(row):\n",
    "    geostring=row['Geometry [WKT]']\n",
    "    geostring=geostring.replace(\"LINESTRING (\",\"\").replace(\")\",\"\").replace(\", \",\",\").replace(\" \",\",\")\n",
    "    return geostring.split(\",\")\n",
    "\n",
    "def make_links_file_for_leaflet():\n",
    "    ### Making Maps\n",
    "    ## Saving a CSV with all the delivery links so it can be mapped in leaflet\n",
    "    tech__loc_and_year_df=seraflow_full.groupby(['Technology','Network_ID','Year']).sum()\n",
    "    ### export this for use in leaflet by scenario\n",
    "    ## export H2_kg\n",
    "    tech__loc_and_year_df=tech__loc_and_year_df[['H2_kg']].reset_index()\n",
    "    #add in nodes\n",
    "    tech__loc_and_year_df=tech__loc_and_year_df.merge(nodes_df,on=\"Network_ID\",how=\"left\")\n",
    "\n",
    "    ## add in links\n",
    "    ## TODO: need to get net flows for links.csv file which is used to generate maps\n",
    "    links_df2=links_df[['Network ID','From_lon','From_lat','To_lon','To_lat','Length [km]']].rename(columns={'Network ID':'Network_ID'})\n",
    "    links_df2[['From_lon','From_lat','To_lon','To_lat']]=links_df2[['From_lon','From_lat','To_lon','To_lat']].astype(float)\n",
    "    tech__loc_and_year_df=tech__loc_and_year_df.merge(links_df2,on=\"Network_ID\",how=\"left\")\n",
    "    tech__loc_and_year_df[['From_lon','From_lat','To_lon','To_lat','lat','lon']]=tech__loc_and_year_df[['From_lon','From_lat','To_lon','To_lat','lat','lon']].round(decimals = 3)\n",
    "    deliverylinks=['GH2 Pipeline (transmission)','Linepack pipeline (transmission)','LH2 Truck Link Var','GH2 Truck Link Var']\n",
    "    delivery_link_df=tech__loc_and_year_df[tech__loc_and_year_df['Technology'].isin(deliverylinks)]\n",
    "    delivery_link_df['Technology']=delivery_link_df['Technology'].replace({'LH2 Truck Link Var':'LH2','GH2 Truck Link Var':'GH2','GH2 Pipeline (transmission)':'pipeline','Linepack pipeline (transmission)':'linepack'})\n",
    "    delivery_link_df['Technology'].value_counts()\n",
    "    delivery_link_df['Length [km]']=delivery_link_df['Length [km]'].astype(int)\n",
    "    delivery_link_df.to_csv(outputsfolder+\"links.csv\",index=False)\n",
    "    points=['LH2 Station (gas dispensing)','GH2 Pipeline Station (700bar)','GH2 Truck Station (700bar)',\n",
    "           'Central Grid Electrolysis (PEM)','Central Ren Electrolysis (PEM-REN)','Central Natural Gas Reforming w/CCS']\n",
    "    points_df=tech__loc_and_year_df[tech__loc_and_year_df['Technology'].isin(points)]\n",
    "    points_df['Technology']=points_df['Technology'].replace({'LH2 Station (gas dispensing)':'LH2','GH2 Pipeline Station (700bar)':'pipeline','GH2 Truck Station (700bar)':'GH2',\n",
    "           'Central Grid Electrolysis (PEM)':'PEM','Central Ren Electrolysis (PEM-REN)':'PEM-REN','Central Natural Gas Reforming w/CCS':'SMRwCCS'})\n",
    "    # display(points_df.head())\n",
    "    points_df['H2_kg']=points_df['H2_kg'].astype(int)\n",
    "    points_df=points_df[['Technology','Network_ID','Year','H2_kg','lat','lon']]\n",
    "    points_df.to_csv(outputsfolder+\"points.csv\",index=False)\n",
    "    \n",
    "def calculate_flow_difference(group):\n",
    "    return group['H2_kg'].max() - group['H2_kg'].min()\n",
    "\n",
    "def make_links_file_for_leaflet2():\n",
    "    ### Making Maps\n",
    "    ## Saving a CSV with all the delivery links so it can be mapped in leaflet\n",
    "    tech__loc_and_year_df=seraflow_full.groupby(['Technology','Network_ID','Year']).sum()\n",
    "    ### export this for use in leaflet by scenario\n",
    "    ## export H2_kg\n",
    "    tech__loc_and_year_df=tech__loc_and_year_df[['H2_kg']].reset_index()\n",
    "    #add in nodes\n",
    "    tech__loc_and_year_df=tech__loc_and_year_df.merge(nodes_df,on=\"Network_ID\",how=\"left\")\n",
    "\n",
    "    ## Making Links File\n",
    "    del_links_df=seraflow_full[seraflow_full['Infrastucture_ID'].str.contains(\"link_\")].sort_values(\"Network_ID\")\n",
    "    del_links_df['fromLoc']=del_links_df[\"Infrastucture_ID\"].str.extract(r'INFR_(.*?)_link')\n",
    "    del_links_df=del_links_df.groupby(['Technology','Network_ID','Year','fromLoc']).sum()\n",
    "    del_links_df=del_links_df.reset_index()\n",
    "\n",
    "\n",
    "    links_with_multiple_From_values = del_links_df.groupby(['Technology', 'Network_ID', 'Year']).filter(lambda x: x['fromLoc'].nunique() > 1)\n",
    "\n",
    "    del_links_df2 = links_with_multiple_From_values.groupby(['Technology', 'Network_ID', 'Year']).apply(calculate_flow_difference).reset_index()\n",
    "    del_links_df2.columns = ['Technology', 'Network_ID', 'Year', 'H2_kg']\n",
    "    links_w_o_dupes=~del_links_df.duplicated(subset=['Technology', 'Network_ID', 'Year'], keep=False)\n",
    "    single_links=del_links_df[links_w_o_dupes][['Technology', 'Network_ID', 'Year', 'H2_kg']]\n",
    "    del_links_df2=del_links_df2.append(single_links)\n",
    "    links_df2=links_df[['Network ID','From_lon','From_lat','To_lon','To_lat','Length [km]']].rename(columns={'Network ID':'Network_ID'})\n",
    "    links_df2[['From_lon','From_lat','To_lon','To_lat']]=links_df2[['From_lon','From_lat','To_lon','To_lat']].astype(float)\n",
    "    del_links_df2=del_links_df2.merge(links_df2,on=\"Network_ID\",how=\"left\")\n",
    "    del_links_df2[['From_lon','From_lat','To_lon','To_lat']]=del_links_df2[['From_lon','From_lat','To_lon','To_lat']].round(decimals = 3)\n",
    "\n",
    "    ## add in links\n",
    "    ## TODO: need to get net flows for links.csv file which is used to generate maps\n",
    "\n",
    "    deliverylinks=['GH2 Pipeline (transmission)','Linepack pipeline (transmission)','LH2 Truck Link Var','GH2 Truck Link Var']\n",
    "\n",
    "\n",
    "    # delivery_link_df=tech__loc_and_year_df[tech__loc_and_year_df['Technology'].isin(deliverylinks)]\n",
    "\n",
    "\n",
    "    del_links_df2['Technology']=del_links_df2['Technology'].replace({'LH2 Truck Link Var':'LH2','GH2 Truck Link Var':'GH2','GH2 Pipeline (transmission)':'pipeline','Linepack pipeline (transmission)':'linepack'})\n",
    "    del_links_df2['Technology'].value_counts()\n",
    "    del_links_df2['Length [km]']=del_links_df2['Length [km]'].astype(int)\n",
    "    del_links_df2.to_csv(outputsfolder+\"links.csv\",index=False)\n",
    "\n",
    "    \n",
    "    tech__loc_and_year_df=tech__loc_and_year_df.merge(links_df2,on=\"Network_ID\",how=\"left\")\n",
    "    tech__loc_and_year_df[['From_lon','From_lat','To_lon','To_lat','lat','lon']]=tech__loc_and_year_df[['From_lon','From_lat','To_lon','To_lat','lat','lon']].round(decimals = 3)\n",
    "    points=['LH2 Station (gas dispensing)','GH2 Pipeline Station (700bar)','GH2 Truck Station (700bar)',\n",
    "           'Central Grid Electrolysis (PEM)','Central Ren Electrolysis (PEM-REN)','Central Natural Gas Reforming w/CCS']\n",
    "    points_df=tech__loc_and_year_df[tech__loc_and_year_df['Technology'].isin(points)]\n",
    "    points_df['Technology']=points_df['Technology'].replace({'LH2 Station (gas dispensing)':'LH2','GH2 Pipeline Station (700bar)':'pipeline','GH2 Truck Station (700bar)':'GH2',\n",
    "           'Central Grid Electrolysis (PEM)':'PEM','Central Ren Electrolysis (PEM-REN)':'PEM-REN','Central Natural Gas Reforming w/CCS':'SMRwCCS'})\n",
    "    # display(points_df.head())\n",
    "    points_df['H2_kg']=points_df['H2_kg'].astype(int)\n",
    "    points_df=points_df[['Technology','Network_ID','Year','H2_kg','lat','lon']]\n",
    "    points_df.to_csv(outputsfolder+\"points.csv\",index=False)\n",
    "\n",
    "\n",
    "def makeDeliveryModeLevCostFigDF(components,stacked,name):\n",
    "    tmp=seraflow_full[(seraflow_full['Technology'].isin(components))]\n",
    "    \n",
    "    tmp_summary=tmp.groupby(['Technology','Year']).sum()\n",
    "    tmp_summary['Lev Cost']=tmp_summary['Total Annual Cost']/(tmp_summary['Flow_kg']+tmp_summary['Production_kg'])\n",
    "    tmp_summary['CF']=(tmp_summary['Flow_kg']+tmp_summary['Production_kg'])/tmp_summary['Nameplate_Capacity']        \n",
    "    tmp_summary=tmp_summary.reset_index()\n",
    "    # display(tmp_summary)\n",
    "    \n",
    "    df_all=pd.DataFrame()\n",
    "    for i in range(0,len(components)):\n",
    "        df_all=pd.concat([df_all,tmp_summary[tmp_summary['Technology']==components[i]]])\n",
    "    \n",
    "    df_all=df_all.pivot(index='Year',columns='Technology',values='Lev Cost')\n",
    "    df_all=df_all.fillna(0)\n",
    "#     display(df_all)\n",
    "    if df_all.shape!=(0,0):\n",
    "        ax = df_all.plot.bar(stacked=stacked,figsize=(12, 6))\n",
    "        ax.set_ylabel(name+\"Levelized Cost ($/kg)\")\n",
    "        if hidefigs:\n",
    "            plt.close()\n",
    "        plt.savefig(outputsfolder+name+'lev cost.png', dpi=300)\n",
    "    \n",
    "    return tmp_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791de17-a0e5-4a8d-87d7-f3512e224649",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# CELL #3 # This is the code to process the output folders in cell #1\n",
    "###########\n",
    "\n",
    "######\n",
    "# this parameter determines whether you turn each line in the construction file \n",
    "# which represents a single technology built in a given year into\n",
    "# a series of technologies with a line for every year of it's lifetime\n",
    "# this is done because when merged with the flow file, sometimes the flow is variable\n",
    "# and isn't used each year.  in this case, the capital costs aren't tallied correctly\n",
    "# b/c they are only tallied in years with flow instead of every year in it's lifetime\n",
    "expand_construction_df=True\n",
    "#Hide figures?\n",
    "hidefigs=False\n",
    "\n",
    "overallstart = time.perf_counter()\n",
    "yrs=[2030,2040,2050]\n",
    "\n",
    "plantlist=[\"Central Grid Electrolysis (PEM)\",\"Central Ren Electrolysis (PEM-REN)\",\"Central Natural Gas Reforming w/CCS\",\"Central Natural Gas Reforming (no CCS)\"]\n",
    "stationlist=['GH2 Truck Station (700bar)','LH2 Station (gas dispensing)','GH2 Pipeline Station (700bar)']\n",
    "delivery_components=['GH2 Truck','GH2 Truck Link Var','GH2 Pipeline Truck Terminal','LH2 Truck','LH2 Truck Link Var','LH2 Truck Terminal w/storage','GH2 Pipeline Compressor','GH2 Pipeline (transmission)','Linepack pipeline (transmission)','GH2 Pipeline Nodal Storage','GH2 Pipeline Salt Cavern Storage']\n",
    "gastruck_components=['GH2 Truck Station (700bar)','GH2 Truck','GH2 Truck Link Var','GH2 Pipeline Truck Terminal']\n",
    "liqtruck_components=['LH2 Station (gas dispensing)','LH2 Truck','LH2 Truck Link Var','LH2 Truck Terminal w/storage']\n",
    "pipeline_components=['GH2 Pipeline Station (700bar)','GH2 Pipeline Compressor','GH2 Pipeline (transmission)','Linepack pipeline (transmission)','GH2 Pipeline Nodal Storage','GH2 Pipeline Salt Cavern Storage']\n",
    "central_electrolysis_components=['Central Grid Electrolysis (PEM)',\"Central Ren Electrolysis (PEM-REN)\"]\n",
    "central_SMR_components=['Central Natural Gas Reforming w/CCS',\"Central Natural Gas Reforming (no CCS)\"]\n",
    "all_components=plantlist+gastruck_components+liqtruck_components+pipeline_components\n",
    "\n",
    "initDeliveryNetworks()\n",
    "\n",
    "# for i in range(0,len(files)):\n",
    "for i in range(3,4):\n",
    "    starttimer = time.perf_counter()\n",
    "    # starttimer = time.perf_counter()\n",
    "    folder=files[i]['folder']\n",
    "    print(folder)\n",
    "    outputsfolder=folder+'outputs/'\n",
    "    inputsfolder=folder+'inputs/'\n",
    "    \n",
    "    #grabs feedstock prices and inputs from the input files (using scenario.YAML)\n",
    "    feedstockfolders=get_key_files_from_YAML()\n",
    "    \n",
    "    #GET MATERIAL/ENERGY INPUT FILES INTO DF\n",
    "    delinputs_df=pd.read_csv(folder+feedstockfolders[0], sep='\\t')\n",
    "    prodinputs_df=pd.read_csv(folder+feedstockfolders[1], sep='\\t')\n",
    "    #GET LOCATION OF EVERY NETWORK ID (TAZ, LINK) # needs to be updated if/when links have multiple regions\n",
    "    zones_df=pd.read_csv(folder+feedstockfolders[3], sep='\\t')\n",
    "    nodes_df=pd.read_csv(folder+feedstockfolders[4], sep='\\t')\n",
    "    nodes_df=nodes_df.rename(columns={'Network ID':'Network_ID','X':'lon','Y':'lat'})[['Network_ID','lat','lon']]\n",
    "    links_df=pd.read_csv(folder+feedstockfolders[6],sep='\\t')\n",
    "    links_df[['From_lon','From_lat','To_lon','To_lat']]=links_df.apply(parse_geometry_col,axis=1,result_type='expand')\n",
    "    links_df['Length [km]']=links_df['Length [km]'].astype(int)\n",
    "    network_dict=zones_df.set_index('Network ID').to_dict()['Zone']\n",
    "    TAZ_demand_df=pd.read_csv(folder+feedstockfolders[5],sep='\\t')\n",
    "    annual_station_df=TAZ_demand_df.groupby('Year').sum()[['Fueling-Station Demand [kg]']]\n",
    "    \n",
    "    #join the list of unique input materials\n",
    "    listofinputs=set(list(delinputs_df['Material'].unique())).union(set(list(prodinputs_df['Material'].unique())))\n",
    "    print(listofinputs)\n",
    "    # list of input materials\n",
    "    listofinputs.remove('Salt Cavern Available [kg]')\n",
    "    all_inputs_df=pd.concat([prodinputs_df,delinputs_df])\n",
    "    all_inputs_df[all_inputs_df['Technology'].isin(all_components)]\n",
    "    all_inputs_df=all_inputs_df[all_inputs_df['Technology'].isin(all_components)]\n",
    "    all_inputs_df=all_inputs_df[all_inputs_df['Material'].isin(listofinputs)]\n",
    "    \n",
    "    #GET PRICE FILE INTO DF\n",
    "    prices_df=pd.read_csv(folder+feedstockfolders[2], sep='\\t')\n",
    "    ## Make dataframe into dict (faster)\n",
    "    mats=list(prices_df['Material'].unique())\n",
    "    zones=list(prices_df['Zone'].unique())\n",
    "    prices_dict={}\n",
    "    for mi in range(0,len(mats)):\n",
    "        prices_dict[mats[mi]]={}\n",
    "        for mj in range(0,len(zones)):\n",
    "            prices_dict[mats[mi]][zones[mj]]={}\n",
    "    # display(prices_dict)\n",
    "    # for ri in range(0,len(prices_df)):\n",
    "    for index, row in prices_df.iterrows():\n",
    "        # row=prices_df.iloc[[ri]]\n",
    "        prices_dict[row['Material']][row['Zone']][row['Year']]=row['Price [$/unit]']\n",
    "        # prices_dict[row['Material'].iloc[0]][row['Zone'].iloc[0]][row['Year'].iloc[0]]=row['Price [$/unit]'].iloc[0]\n",
    "        #prices_dict[material][zone][year]\n",
    "        \n",
    "    # READ IN CONSTRUCTION AND FLOW FILES \n",
    "    prefix=files[i]['code']+\"_\"\n",
    "    seraconstruction=pd.read_csv(outputsfolder+files[i]['const'], sep='\\t')    \n",
    "    seraflow=pd.read_csv(outputsfolder+files[i]['flow'], sep='\\t')\n",
    "    \n",
    "    #add Levelized Cost Calculations\n",
    "    seraconstruction['DailyCap']=seraconstruction['Nameplate_Capacity']/365000\n",
    "    seraconstruction['EndYear']=seraconstruction['Year']+seraconstruction['Lifetime']\n",
    "    seraconstruction['CRF']=CRF(.1,seraconstruction['Lifetime'])\n",
    "    seraconstruction['Annual Cap']=seraconstruction['CRF']*seraconstruction['Capital_Cost']\n",
    "    seraconstruction['Capital & Fixed Annual Cost']=seraconstruction['Annual Cap']+seraconstruction['Fixed_Operating_Cost']\n",
    "    \n",
    "    ######################################################################################################\n",
    "    # This section is added to fix the issue with flow years not occuring in every year of \n",
    "    # a technology's lifetime\n",
    "    # merging the construction and flow files (either with multiple lines per constructed \n",
    "    # technology (one for each year of lifetime) or just one\n",
    "    ######################################################################################################\n",
    "    if expand_construction_df==False:\n",
    "        #this is what the section of code used to look like - merge construction and flow files\n",
    "        seraconstruction_key=seraconstruction[['Infrastucture_ID','Network_ID','Nameplate_Capacity','DailyCap','Length','Variable_Operating_Cost','Storage_Capacity','EndYear','CRF','Annual Cap','Fixed_Operating_Cost','Capital & Fixed Annual Cost']]\n",
    "        seraflow_full=seraflow.merge(seraconstruction_key, on=\"Infrastucture_ID\", how='left')\n",
    "    elif expand_construction_df==True:\n",
    "        #this is waht this section of code is being replaced with\n",
    "        # get a list of all technologies built\n",
    "        # list_of_InfraIDs=list(seraconstruction['Infrastucture_ID'])\n",
    "        # run down the list of technologies and expand so there is 1 row for each year of it's lifetime (to 2050)\n",
    "        \n",
    "        expanded_construction_data=[seraconstruction]\n",
    "        print(\"starting expansion\", end=\" \")\n",
    "        # for id in list_of_InfraIDs: # old   #SPEEDED UP BY USING ITERROWS\n",
    "        for index, row in seraconstruction.iterrows():\n",
    "            #grab the one row\n",
    "            # tech_row=seraconstruction[seraconstruction['Infrastucture_ID']==id] # old \n",
    "            tech_row=row.copy()\n",
    "            # display(tech_row)\n",
    "            # get the years to populate for lifetime\n",
    "            tech_yr=tech_row['Year']\n",
    "            tech_life=tech_row['Lifetime']\n",
    "            if tech_life<100:\n",
    "                tech_range=range(int(tech_yr+1),min(int(tech_yr+tech_life),2051))\n",
    "                tech_len=len(tech_range)\n",
    "                # repeat this row for each year of lifetime\n",
    "                # tech_df=tech_row.loc[tech_row.index.repeat(tech_len)]\n",
    "                # print(tech_row)\n",
    "                tech_rowdf=pd.DataFrame(tech_row).transpose()\n",
    "                tech_df=tech_rowdf.loc[tech_rowdf.index.repeat(tech_len)]\n",
    "                #replace years with range of years (not including initial construciton year)\n",
    "                tech_df['Year']=list(tech_range)\n",
    "                #add this to the list of\n",
    "                expanded_construction_data.append(tech_df.copy())\n",
    "                # print(len(expanded_construction_data),len(tech_df))\n",
    "        print(\" - ended\", end=\" \")\n",
    "        endtimer = time.perf_counter()\n",
    "        print(round(endtimer-starttimer), \"seconds\", end=\" \")\n",
    "        \n",
    "        #once done all of the individual row expansion, concatenate everything\n",
    "        seraconstruction_exp=pd.concat(expanded_construction_data)\n",
    "        seraconstructionlength=len(seraconstruction_exp)\n",
    "        \n",
    "        #subset columns\n",
    "        seraflow_key=seraflow[['Variable','Infrastucture_ID','Year','Production_kg','Flow_kg','Loss_kg','Cost','Salvage_Value']]\n",
    "        seraconstruction_key=seraconstruction_exp[['Infrastucture_ID','Network_ID','Technology','Year','Lifetime','Nameplate_Capacity','Maximum_Utilization','DailyCap','Length','Variable_Operating_Cost','Storage_Capacity','EndYear','CRF','Annual Cap','Fixed_Operating_Cost','Capital & Fixed Annual Cost']]\n",
    "        seraflow_full=seraflow_key.merge(seraconstruction_key,on=['Infrastucture_ID','Year'],how='right')\n",
    "        # fill in blank data\n",
    "        seraflow_full=seraflow_full.fillna(0)\n",
    "        seraflow_full['Variable']=seraflow_full['Variable'].replace(0,'')\n",
    "        seraflow_full['Year']=seraflow_full['Year'].astype(int)\n",
    "        \n",
    "    # Calculate all costs\n",
    "    seraflow_full = seraflow_full.rename(columns={'Variable_Operating_Cost': 'Var_Op_Cost_per_kg'})\n",
    "    seraflow_full['H2_kg']=seraflow_full['Flow_kg']+seraflow_full['Production_kg']\n",
    "    seraflow_full['TotalVarCost']=seraflow_full['Var_Op_Cost_per_kg']*seraflow_full['H2_kg']\n",
    "    #drop rows with no costs and no flows (mostly unused truck capacity, because trucks have no capital costs)\n",
    "    noflow_nocost=seraflow_full[(seraflow_full['Capital & Fixed Annual Cost']==0) & (seraflow_full['H2_kg']==0)].index\n",
    "    seraflow_full=seraflow_full.drop(noflow_nocost)\n",
    "    seraflow_full['Category']=seraflow_full.apply(get_category1,axis=1)\n",
    "    seraflow_full['Pathway']=seraflow_full.apply(get_Pathway,axis=1)\n",
    "\n",
    "    # CALCULATE MATERIAL/FEEDSTOCK ANNUAL COSTS HERE\n",
    "    # Make Multiple Columns: Material X, Material X Price, Material Y, Material Y Price,. . . \n",
    "    # ADD MATERIAL AND PRICE CELLS TO DF\n",
    "    # from testing cell #4\n",
    "\n",
    "    print(\"starting feedstock part \", end=\" \")\n",
    "    for item in listofinputs:\n",
    "        seraflow_full[item]=0\n",
    "        item_price=item.replace(\" [\",\"-price [$/\")\n",
    "        seraflow_full[item_price]=0\n",
    "    \n",
    "    techs_w_inputs_list=list(all_inputs_df['Technology'].unique())\n",
    "    techs_w_inputs_dict={}\n",
    "    ind_i=0\n",
    "    twopct=round(len(seraflow_full)*.02)\n",
    "    tech_feedstock_input_dict={}\n",
    "    ##STEP THROUGH EACH TECHNOLOGY TYPE \n",
    "    for tech in techs_w_inputs_list:\n",
    "        tech_feedstock_input_dict[tech]={}\n",
    "        tech_x_inputs_df=all_inputs_df.query('Technology==@tech')\n",
    "        tech_x_inputs_list=list(tech_x_inputs_df['Material'].unique())\n",
    "        techs_w_inputs_dict[tech]=tech_x_inputs_list\n",
    "    \n",
    "        #from testing cell #5\n",
    "        # tech_x_serafull=seraflow_full[seraflow_full['Technology']==tech & seraflow_full['H2_kg']>0]\n",
    "        #Only calculate feedstock costs for technologies with non-zero H2 flows (not idled technologies)\n",
    "        tech_x_serafull=seraflow_full.query('Technology==@tech and H2_kg>0')\n",
    "        tech_feedstock_inputs=techs_w_inputs_dict[tech]\n",
    "        \n",
    "        #### MAKE A DICT THAT INCLUDES:\n",
    "        ####     LIST OF ALL YEARS FOR EACH INPUT TECHNOLOGY / FEEDSTOCK COMBO\n",
    "        ####     TABLES OF FEEDSTOCK INPUT TABLES FOR EACH INPUT TECHNOLOGY / FEESTOCK / YR COMBO (includes different sizes)\n",
    "        # faster to pregenerate all these tables and lists once instead of for each row \n",
    "        for feedstock in tech_feedstock_inputs:\n",
    "            tech_feedstock_input_dict[tech][feedstock]={}\n",
    "            tech_feedstock_input_dict[tech][feedstock]['Years']=list(all_inputs_df[(all_inputs_df['Technology']==tech) & (all_inputs_df['Material']==feedstock)].Year.unique())\n",
    "            tech_feedstock_input_dict[tech][feedstock]['Tables']={}\n",
    "            for yr in tech_feedstock_input_dict[tech][feedstock]['Years']:\n",
    "                tech_feedstock_input_dict[tech][feedstock]['Tables'][yr]=all_inputs_df[(all_inputs_df['Technology']==tech) & (all_inputs_df['Material']==feedstock) & (all_inputs_df['Year']==yr)]\n",
    "        # display(tech_feedstock_input_dict)\n",
    "        ## STEP THROUGH EACH INSTANCE OF THE TECHNOLOGY - ONE ROW\n",
    "        # for i in range(0,len(tech_x_serafull)):\n",
    "        for index, row in tech_x_serafull.iterrows():\n",
    "            # ind_i+=1\n",
    "            # if ind_i%twopct==0:\n",
    "            #     print(ind_i/twopct*.02, end=\" \")\n",
    "            # rowtech=tech_x_serafull.iloc[[i]]\n",
    "            rowtech = row\n",
    "            \n",
    "            # if (rowtech['H2_kg'].iloc[0])>0:\n",
    "            # techind=rowtech.index[0]\n",
    "            techind=index\n",
    "            techyr=rowtech['Year']\n",
    "            techcap=rowtech['Nameplate_Capacity']\n",
    "            techreg=rowtech['Network_ID']\n",
    "            techzone=network_dict[techreg]\n",
    "            seraflow_full.loc[techind,'Zone']=techzone\n",
    "            ## WITHIN EACH ROW, STEP THROUGH DIFFERENT INPUT FEEDSTOCKS\n",
    "            for feedstock in tech_feedstock_inputs:\n",
    "                ##### GET FEEDSTOCK INTENSITY\n",
    "                # tech_x_input_yrs=list(tech_x_inputs_df[tech_x_inputs_df['Material']==feedstock]['Year'].unique())\n",
    "                \n",
    "                \n",
    "                tech_x_input_yrs=tech_feedstock_input_dict[tech][feedstock]['Years']\n",
    "                closest_year=get_nearest_year_before(techyr,tech_x_input_yrs)\n",
    "                # feedstock_lookup_table=tech_x_inputs_df.query('Year==@closest_year & Material==@feedstock')\n",
    "                # feedstock_lookup_table=tech_x_inputs_df[(tech_x_inputs_df['Year']==closest) & (tech_x_inputs_df['Material']==feedstock)]\n",
    "                feedstock_lookup_table=tech_feedstock_input_dict[tech][feedstock]['Tables'][closest_year]\n",
    "                # display(feedstock_lookup_table)\n",
    "                if feedstock=='Diesel [gal]':\n",
    "                    feedstock_cons=table_scale_interpolation_v2(techcap,'Nameplate Capacity [kg/yr]','Consumption [unit/km/kg]',feedstock_lookup_table,0)\n",
    "                else:\n",
    "                    feedstock_cons=table_scale_interpolation_v2(techcap,'Nameplate Capacity [kg/yr]','Consumption [unit/kg]',feedstock_lookup_table,0)\n",
    "                seraflow_full.loc[techind,feedstock]=feedstock_cons\n",
    "                ##### GET PRICE OF FEEDSTOCK IN REGION\n",
    "                # price_lookup_table_feedstock_y=prices_df[prices_df['Material']==feedstock]\n",
    "                # #get feedstock price that is specific to region of technology and year\n",
    "                # feedstockprice=price_lookup_table_feedstock_y.query(\"Zone==@techzone and Year==@techyr\")['Price [$/unit]'].iloc[0]\n",
    "                #USE DICT instead of DF\n",
    "                feedstockprice=prices_dict[feedstock][techzone][techyr]\n",
    "                feedstock_price_col_name=feedstock.replace(\" [\",\"-price [$/\")\n",
    "                seraflow_full.loc[techind,feedstock_price_col_name]=feedstockprice\n",
    "    ##### ADD COSTS TO GET TOTAL ANNUAL COSTS\n",
    "    seraflow_full['Feedstock Annual Cost']=(seraflow_full['H2_kg'])*(seraflow_full['Water Total [gal]']*seraflow_full['Water Total-price [$/gal]']+seraflow_full['Diesel [gal]']*seraflow_full['Diesel-price [$/gal]']+seraflow_full['Natural Gas (Industrial) [MMBtu]']*seraflow_full['Natural Gas (Industrial)-price [$/MMBtu]']+seraflow_full['Electricity (Industrial) [kWh]']*seraflow_full['Electricity (Industrial)-price [$/kWh]']+seraflow_full['Electricity (Renewable) [kWh]']*seraflow_full['Electricity (Renewable)-price [$/kWh]'])\n",
    "    seraflow_full['O&M Cost (Fix+Var)']=seraflow_full['Fixed_Operating_Cost']+seraflow_full['TotalVarCost']\n",
    "    seraflow_full['Total Annual Cost']=seraflow_full['Capital & Fixed Annual Cost']+seraflow_full['TotalVarCost']+seraflow_full['Feedstock Annual Cost']\n",
    "    \n",
    "    endtimer=time.perf_counter()\n",
    "    print(\"final\", round(endtimer-starttimer), \"seconds\", end=\" \")\n",
    "    seraflow_full.to_csv(outputsfolder+\"seraflow_full.csv\",index=False)\n",
    "    endtimer=time.perf_counter()\n",
    "    print(\"total\", round(endtimer-overallstart), \"sec\", end=\" \")\n",
    "    \n",
    "    ##### Make Graphs - put functions here ######\n",
    "    graph_aggregate_lev_cost()\n",
    "    graph_annual_costs()\n",
    "    graph_production_delivery_mix()\n",
    "    graph_delivery_distances()\n",
    "    production_location()\n",
    "    caps_and_flows()\n",
    "    storageflows()\n",
    "    category_levelized_cost()\n",
    "    CapOpFeed_levelized_cost()\n",
    "    pathway_levelized_cost()\n",
    "    make_links_file_for_leaflet2()\n",
    "    gastruck_summary=makeDeliveryModeLevCostFigDF(gastruck_components,True,\"GH2 \")\n",
    "    liqtrucks_summary=makeDeliveryModeLevCostFigDF(liqtruck_components,True,\"LH2 \")\n",
    "    pipelines_summary=makeDeliveryModeLevCostFigDF(pipeline_components,True,\"Pipeline \")\n",
    "    production_summary=makeDeliveryModeLevCostFigDF(plantlist,False,\"Production \")\n",
    "    #############################################\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
